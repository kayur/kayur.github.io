@inproceedings{Gordon2019,
abstract = {We have limited understanding of how older adults use smart-phones, how their usage differs from younger users, and the causes for those differences. As a result, researchers and developers may miss promising opportunities to support older adults or offer solutions to unimportant problems. To characterize smartphone usage among older adults, we collected iPhone usage data from 84 healthy older adults over three months. We find that older adults use fewer apps, take longer to complete tasks, and send fewer messages. We use cognitive test results from these same older adults to then show that up to 79{\%} of these differences can be explained by cognitive decline, and that we can predict cognitive test performance from smartphone usage with 83{\%} ROCAUC. While older adults differ from younger adults in app usage behavior, the "cognitively young" older adults use smartphones much like their younger counterparts. Our study suggests that to better support all older adults, researchers and developers should consider the full spectrum of cognitive function.},
author = {Gordon, Mitchell L. and Gatys, Leon and Guestrin, Carlos and Bigham, Jeffrey P. and Trister, Andrew and Patel, Kayur},
booktitle = {CHI},
doi = {10.1145/3290605.3300398},
isbn = {9781450359702},
pages = {1--12},
title = {{App Usage Predicts Cognitive Ability in Older Adults}},
url = {chi2019.pdf},
year = {2019}
}
@inproceedings{Kim2015,
abstract = {The majority of machine learning research has been fo- cused on building models and inference techniques with sound mathematical properties and cutting edge perfor- mance. Little attention has been devoted to the develop- ment of data representation that can be used to improve a user's ability to interpret the data and machine learn- ing models to solve real-world problems. In this paper, we quantitatively and qualitatively evaluate an efficient, accurate and scalable feature-compression method us- ing latent Dirichlet allocation for discrete data. This representation can effectively communicate the charac- teristics of high-dimensional, complex data points. We show that the improvement of a user's interpretability through the use of a topic modeling-based compres- sion technique is statistically significant, according to a number of metrics, when compared with other repre- sentations. Also, we find that this representation is scal- able â€” it maintains alignment with human classifica- tion accuracy as an increasing number of data points are shown. In addition, the learned topic layer can semanti- cally deliver meaningful information to users that could potentially aid human reasoning about data characteris- tics in connection with compressed topic space.},
author = {Kim, Been and Patel, Kayur and Rostamizadeh, Afshin and Shah, Julie A},
booktitle = {AAAI},
isbn = {9781577357018},
keywords = {Machine Learning Applications Track},
title = {{Scalable and Interpretable Data Representation for High-Dimensional, Complex Data}},
url = {aaai2015.pdf},
year = {2015}
}
@inproceedings{Asuncion2014,
abstract = {Google Research recently tested a massive online class model for an internal engineering education program, with machine learning as the topic, that blended theoretical concepts and Google-specific software tool tutorials. The goal of this training was to foster engineering capacity to leverage machine learning tools in future products. The course was delivered both synchronously and asynchronously, and students had the choice between studying independently or participating with a group. Since all students are company employees, unlike most publicly offered MOOCs we can continue to measure the students' behavioral change long after the course is complete. This paper describes the course, outlines the available data set and presents directions for analysis.},
author = {Asuncion, Arthur and de Haan, Jac and Mohri, Mehryar and Patel, Kayur and Rostamizadeh, Afshin and Syed, Umar and Wong, Lauren},
booktitle = {Learning at Scale (Work in Progress)},
doi = {10.1145/2556325.2567874},
isbn = {9781450326698},
title = {{Corporate Learning at Scale}},
url = {l@s2014.pdf},
year = {2014}
}
@phdthesis{Patel2012,
author = {Patel, Kayur},
school = {University of Washington},
title = {{Lowering the Barrier to Applying Machine Learning}},
url = {thesis.pdf},
year = {2012}
}
@inproceedings{bib:Patel2011,
author = {Patel, Kayur and Drucker, Steven M. and Fogarty, James and Kapoor, Ashish and Tan, Desney S.},
booktitle = {IJCAI},
file = {:Users/kayur/Library/Application Support/Mendeley Desktop/Downloaded/Patel et al. - 2008 - Using Multiple Models to Understand Data.pdf:pdf},
title = {{Using Multiple Models to Understand Data}},
url = {ijcai2011.pdf},
year = {2011}
}
@inproceedings{bib:Patel2010,
address = {New York, New York, USA},
author = {Patel, Kayur and Bancroft, Naomi and Drucker, Steven M. and Fogarty, James and Ko, Amy J. and Landay, James A.},
booktitle = {UIST},
doi = {10.1145/1866029.1866038},
file = {:Users/kayur/Library/Application Support/Mendeley Desktop/Downloaded/Patel et al. - 2010 - Gestalt Integrated Support for Implementation and Analysis in Machine Learning ProcessesNo Title.pdf:pdf},
isbn = {9781450302715},
keywords = {forge:kayur{\_}aaai11{\_}nectar,forge:nonotes,gestalt,kayur:generals,machine learning,software development},
mendeley-tags = {forge:kayur{\_}aaai11{\_}nectar,forge:nonotes,kayur:generals},
month = {oct},
pages = {37--46},
publisher = {ACM Press},
series = {UIST 2010},
shorttitle = {UIST 2010},
title = {{Gestalt: Integrated Support for Implementation and Analysis in Machine Learning}},
url = {uist2010.pdf http://portal.acm.org/citation.cfm?id=1866029.1866038},
year = {2010}
}
@inproceedings{bib:Hoffman2009,
abstract = {Although existing work has explored both information extraction and community content creation, most research has focused on them in isolation. In contrast, we see the greatest leverage in the synergistic pairing of these methods as two interlocking feedback cycles. This paper explores the potential synergy promised if these cycles can be made to accelerate each other by exploiting the same edits to advance both community content creation and learning-based information extraction. We examine our proposed synergy in the context of Wikipedia infoboxes and the Kylin information extraction system. After developing and refining a set of interfaces to present the verification of Kylin extractions as a non primary task in the context of Wikipedia articles, we develop an innovative use of Web search advertising services to study people engaged in some other primary task. We demonstrate our proposed synergy by analyzing our deployment from two complementary perspectives: (1) we show we accelerate community content creation by using Kylin's information extraction to significantly increase the likelihood that a person visiting a Wikipedia article as a part of some other primary task will spontaneously choose to help improve the article's infobox, and (2) we show we accelerate information extraction by using contributions collected from people interacting with our designs to significantly improve Kylin's extraction performance.},
author = {Hoffmann, Raphael and Amershi, Saleema and Patel, Kayur and Wu, Fei and Fogarty, James and Weld, Daniel S.},
booktitle = {CHI},
file = {:Users/kayur/Library/Application Support/Mendeley Desktop/Downloaded/Hoffmann et al. - 2009 - Amplifying community content creation with mixed initiative information extraction.pdf:pdf},
keywords = {community content creation,information extraction,mixed-initiative interfaces},
title = {{Amplifying Community Content Creation with Mixed Initiative Information Extraction}},
url = {chi2009.pdf http://portal.acm.org/citation.cfm?id=1518701.1518986},
year = {2009}
}
@inproceedings{Weld2008,
author = {Weld, Daniel S and Wu, Fei and Adar, Eytan and Amershi, Saleema and Fogarty, James and Hoffmann, Raphael and Patel, Kayur and Skinner, Michael},
booktitle = {AAAI (Senior Papers Track)},
isbn = {978-1-57735-368-3},
pages = {1609--1614},
publisher = {AAAI Press},
series = {AAAI'08},
title = {{Intelligence in Wikipedia}},
url = {aaai2008-senior.pdf http://dl.acm.org/citation.cfm?id=1620270.1620344},
year = {2008}
}
@article{Bailenson2008a,
abstract = {Virtual reality (VR) offers new possibilities for learning, specifically for training individuals to perform physical movements such as physical therapy and exercise. The current article examines two aspects of VR that uniquely contribute to media interactivity: the ability to capture and review physical behavior and the ability to see one's avatar rendered in real time from third person points of view. In two studies, we utilized a state-of-the-art, image-based tele-immersive system, capable of tracking and rendering many degrees of freedom of human motion in real time. In Experi- ment 1, participants learned better in VR than in a video learning condition according to self-report measures, and the cause of the advantage was seeing one's avatar stereoscopically in the third person. In Experiment 2, we added a virtualmirror in the learning environment to further leverage the ability to see oneself from novel angles in real time. Participants learned better in VR than in video according to objective performance measures. Implications for learning via interactive digital media are discussed.},
author = {Bailenson, Jeremy and Patel, Kayur and Nielsen, Alexia and Bajscy, Ruzena and Jung, Sang Hack and Kurillo, Gregorij},
doi = {10.1080/15213260802285214},
isbn = {1521326080228},
issn = {15213269},
journal = {Media Psychology},
pmid = {34320086},
title = {{The Effect of Interactivity on Learning Physical Actions in Virtual Reality}},
url = {media{\_}psychology2008.pdf},
year = {2008}
}
@inproceedings{Patel2008,
abstract = {Statistical machine learning continues to show promise as a tool for addressing complex problems in a variety of domains. An increasing number of developers are therefore looking to use statistical machine learning algorithms within applications. We have conducted two initial studies examining the difficulties that developers encounter when creating a statistical machine learning component of a larger application. We first interviewed researchers with experience integrating statistical machine learning into applications. We then sought to directly observe and quantify some of the behavior described in our interviews using a laboratory study of developers attempting to build a simple application that uses statistical machine learning. This paper presents the difficulties we observed in our studies, discusses current challenges to developer adoption of statistical machine learning, and proposes potential approaches to better supporting developers creating statistical machine learning components of applications. Copyright {\textcopyright} 2008.},
author = {Patel, Kayur and Fogarty, James and Landay, James A and Harrison, Beverly},
booktitle = {AAAI (Nectar Track)},
isbn = {9781577353683},
title = {{Examining Difficulties Software Developers Encounter in the Adoption of Statistical Machine Learning}},
url = {aaai2008-nectar.pdf},
year = {2008}
}
@article{Bailenson2008,
abstract = {Conversations are characterized by an interactional synchrony between verbal and nonverbal behaviors [Kendon, A. (1970). Movement coordination in social interaction: some examples described. Acta Psychologica, 32(2), 101-125]. A subset of these contingent conversational behaviors is direct mimicry. During face to face interaction, people who mimic the verbal [Giles, H., Coupland, J., {\&} Coupland, N. (1991). Accommodation theory: Communication, context, and consequence. In Giles, H., Coupland, J., {\&} Coupland, N. Contexts of accommodation. Developments in applied sociolinguistics. Cambridge: Cambridge University Press] and nonverbal behaviors [Chartrand, T. L., {\&} Bargh, J. A. (1999). The chameleon effect: the perception-behavior link and social interaction. Journal of Personality and Social Psychology, 76, 893-910] gain social advantage. Most research examining mimicry behavior in interaction examines 'implicit mimicry' in which the mimicked individual is unaware of the behavior of the mimicker. In this paper, we examined how effective people were at explicitly detecting mimicking computer agents and the consequences of mimic detection in terms of social influence and interactional synchrony. In Experiment 1, participant pairs engaged in a "one-degree of freedom" Turing Test. When the computer agent mimicked them, users were significantly worse than chance at identifying the other human. In Experiment 2, participants were more likely to detect mimicry in an agent that mirror-mimicked their head movements (three degrees of freedom) than agents that either congruently mimicked their behaviors or mimicked those movements on another rotational axis. We discuss implications for theories of interactivity. {\textcopyright} 2007 Elsevier Ltd. All rights reserved.},
author = {Bailenson, Jeremy N. and Yee, Nick and Patel, Kayur and Beall, Andrew C.},
doi = {10.1016/j.chb.2007.01.015},
isbn = {0747-5632},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Embodied agents,Social interaction,Turing test,Virtual reality},
title = {{Detecting Digital Chameleons}},
url = {computers{\_}in{\_}human{\_}behavior2008.pdf},
year = {2008}
}
@inproceedings{Harada2008,
abstract = {Many mobile machine learning applications require collecting and labeling data, and a traditional GUI on a mobile device may not be an appropriate or viable method for this task. This paper presents an alternative approach to mobile labeling of sensor data called VoiceLabel. VoiceLabel consists of two components: (1) a speech-based data collection tool for mobile devices, and (2) a desktop tool for offline segmentation of recorded data and recognition of spoken labels. The desktop tool automatically analyzes the audio stream to find and recognize spoken labels, and then presents a multimodal interface for reviewing and correcting data labels using a combination of the audio stream, the system's analysis of that audio, and the corresponding mobile sensor data. A study with ten participants showed that VoiceLabel is a viable method for labeling mobile sensor data. VoiceLabel also illustrates several key features that inform the design of other data labeling tools.},
author = {Harada, Susumu and Lester, Jonathan and Patel, Kayur and Saponas, T Scott and Fogarty, James and Landay, James A. and Wobbrock, Jacob O.},
booktitle = {ICMI},
keywords = {data collection,machine learning,mobile devices,sensors,speech recognition},
series = {ICMI '08},
title = {{VoiceLabel: Using Speech to Label Mobile Sensor Data}},
url = {icmi2008.pdf http://portal.acm.org/citation.cfm?id=1452392.1452407},
year = {2008}
}
@inproceedings{bib:Patel2008a,
abstract = {As statistical machine learning algorithms and techniques continue to mature, many researchers and developers see statistical machine learning not only as a topic of expert study, but also as a tool for software development. Extensive prior work has studied software development, but little prior work has studied software developers applying statistical machine learning. This paper presents interviews of eleven researchers experienced in applying statistical machine learning algorithms and techniques to human-computer interaction problems, as well as a study of ten participants working during a five-hour study to apply statistical machine learning algorithms and techniques to a realistic problem. We distill three related categories of difficulties that arise in applying statistical machine learning as a tool for software development: (1) difficulty pursuing statistical machine learning as an iterative and exploratory process, (2) difficulty understanding relationships between data and the behavior of statistical machine learning algorithms, and (3) difficulty evaluating the performance of statistical machine learning algorithms and techniques in the context of applications. This paper provides important new insight into these difficulties and the need for development tools that better support the application of statistical machine learning.},
address = {Florence, Italy},
author = {Patel, Kayur and Fogarty, James and Landay, James A. and Harrison, Beverly},
booktitle = {CHI},
keywords = {forge:kayur{\_}aaai11{\_}nectar,forge:nonotes,kayur:generals,software development,statistical machine learning},
mendeley-tags = {forge:kayur{\_}aaai11{\_}nectar,forge:nonotes,kayur:generals},
pages = {667--676},
series = {CHI 2008},
shorttitle = {CHI 2008},
title = {{Investigating Statistical Machine Learning as a Tool for Software Development}},
url = {chi2008.pdf http://portal.acm.org/citation.cfm?id=1357054.1357160},
year = {2008}
}
@inproceedings{Patel2006a,
abstract = {Navigation services (e.g., in-car navigation systems and on- line mapping sites) compute routes between two locations to help users navigate. However, these routes may direct users along an unfamiliar path when a familiar path exists, or, conversely, may include redundant information that the user al- ready knows. These overly complicated directions increase the cognitive load of the user, which may lead to a dan- gerous driving environment. We have developed a system, called MyRoute, that reduces route complexity by creating user specific routes based on a priori knowledge of familiar routes and landmarks. MyRoute works by compressing well known steps into a single contextualized step and rerouting users along familiar routes.},
author = {Patel, Kayur and Chen, Mike Y. and Smith, Ian and Landay, James A.},
booktitle = {UIST},
doi = {10.1145/1166253.1166282},
isbn = {1595933131},
keywords = {are even worse than,attention,by in-car navigation systems,causing them to lose,driving environment,focus in an eyes-busy,interruptions and distractions caused,than those,users},
title = {{Personalizing Routes}},
url = {uist2006.pdf},
year = {2006}
}
@inproceedings{Patel2006,
abstract = {Fully immersive virtual settings are different from traditional virtual reality settings in that they are able to capture full body motion. This ability allows people to use their full range of physical motion to interact with other avatars, computer controlled agents, and objects in the virtual environment. As such, fully immersive virtual reality presents a novel mediated learning environment in which people can learn physical activities. Capturing human motion for virtual settings has traditionally been a model-based approach where a few degrees (on the order of tens) of freedom are mapped to virtual model. In contrast, we use an image-based solution that sacrifices visual fidelity for motion fidelity and increased degrees of freedom (on the order of hundreds). Due to the difficulties involved with building such an image-based immersive system, very little work has been done to assess the effectiveness of this form of mediated learning. In the current work, participants were taught several tai chi moves in either a 2D video system or a 3D immersive system equipped with features not possible to implement in traditional video systems. We demonstrated via blind coder ratings that people learned more in the immersive virtual reality system than in the 2D video system, and via self-report ratings the social presence was higher as well. We discuss these findings and the resulting implications for designing and testing fully immersive systems.},
author = {Patel, Kayur and Bailenson, Jeremy N and Jung, Sang-Hack and Diankov, Rosen and Bajcsy, Ruzena},
booktitle = {PRESENCE},
keywords = {2,computer vision,for learning physical,full immersion virtual reality,human computer,interaction,learning,mediated learning,motion,repeating a task reinforces,research has shown that,virtual},
title = {{The Effects of Fully Immersive Virtual Reality on the Learning of Physical Tasks}},
url = {presence2006.pdf},
year = {2006}
}
@inproceedings{Bodik2005,
abstract = {Web applications suffer from software and configuration faults that lower their availability. Recovering from failure is dominated by the time interval between when these faults appear and when they are detected by site operators. We introduce a set of tools that augment the ability of operators to perceive the presence of failure: an automatic anomaly detector scours HTTP access logs to find changes in user behavior that are indicative of site failures, and a visualizer helps operators rapidly detect and diagnose problems. Visualization addresses a key question of autonomic computing of how to win operators' confidence so that new tools will be embraced. Evaluation performed using HTTP logs from Ebates.com demonstrates that these tools can enhance the detection of failure as well as shorten detection time. Our approach is application-generic and can be applied to any Web application without the need for instrumentation},
author = {Bod{\'{i}}k, Peter and Friedman, Greg and Biewald, Lukas and Levine, Helen and Candea, George and Patel, Kayur and Tolle, Gilman and Hui, Jon and Fox, Armando and Jordan, Michael I. and Patterson, David},
booktitle = {ICAC},
doi = {10.1109/ICAC.2005.18},
isbn = {0769522769},
title = {{Combining Visualization and Statistical analysis to Improve Operator Confidence and Efficiency for Failure Detection and Localization}},
url = {icac2005.pdf},
year = {2005}
}
@inproceedings{Patel2005,
abstract = {In this paper we propose an active control strategy for scanning laser sensors on autonomous vehicles traveling offroad at high speeds. As speed increases the amount of sensor information about the terrain decreases. We address the problem of sensor .....},
author = {Patel, Kayur and Macklem, Walter and Thrun, Sebastian and Montemerlo, Mike},
booktitle = {ICRA},
doi = {10.1109/ROBOT.2005.1570597},
isbn = {078038914X},
issn = {10504729},
keywords = {Active perception,Active sensing,Active vision,High speed,Offroad},
title = {{Active Sensing for High-Speed Offroad Driving}},
url = {icra2005.pdf},
year = {2005}
}
